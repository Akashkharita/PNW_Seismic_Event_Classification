{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0547958",
   "metadata": {},
   "source": [
    "# Train and evaluate CNN models\n",
    "\n",
    "\n",
    "\n",
    "Author: Akash Kharita\n",
    "\n",
    "Date: 02/28/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e949bd1",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d066669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import obspy\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from scipy.signal import resample\n",
    "# from zenodo_get import zenodo_get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed8eb1",
   "metadata": {},
   "source": [
    "## Importing all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f219ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from design_CNN_models import Archtime\n",
    "# from design_CNN_models import Archtime_do\n",
    "# from design_CNN_models import WaveDecompNet\n",
    "# from design_CNN_models import WaveDecompNet_do\n",
    "# from design_CNN_models import SeismicCNN_batch\n",
    "# from design_CNN_models import SeismicCNN_batch_do\n",
    "# from design_CNN_models import SeismicNet\n",
    "# from design_CNN_models import SeismicNet_do\n",
    "\n",
    "\n",
    "# from neural_network_processing_functions import extract_datasets\n",
    "# from neural_network_processing_functions import train_model\n",
    "# from neural_network_processing_functions import plot_train_val_loss\n",
    "# from neural_network_processing_functions import plot_accuracy\n",
    "# from neural_network_processing_functions import extract_datasets_for_test\n",
    "# from neural_network_processing_functions import train_model_for_test\n",
    "# from neural_network_processing_functions import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# Arch-time from Deepquake paper. \n",
    "# it originally takes 2000 samples as input. \n",
    "\n",
    "# defining a monolithic and fat CNN\n",
    "\n",
    "class Archtime(nn.Module):\n",
    "    def __init__(self, num_classes=4, num_channels = 1, num_features = 5000):\n",
    "        super(Archtime, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_channels = num_channels\n",
    "        # Define the layers of the CNN architecture\n",
    "        self.conv1 = nn.Conv1d(in_channels= num_channels, out_channels=64, kernel_size= 10, stride = 4, padding = 0)       \n",
    "        self.conv2 = nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 10, stride = 2)\n",
    "        self.flatten = nn.Flatten() \n",
    "        self.num_features_after_conv = self.calculate_num_features_after_conv() # automatically calculate the number of features\n",
    "            \n",
    "        self.fc1 = nn.Linear(self.num_features_after_conv, 32)\n",
    "        \n",
    "        self.fc2 = nn.Linear(32,4)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.softmax(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Lets define a function to visualize the activation as well. \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward_conv(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def calculate_num_features_after_conv(self):\n",
    "        # Dummy input to calculate the number of features after convolutional layers\n",
    "        dummy_input = torch.randn(1, self.num_channels, self. num_features)  # Adjust the size based on your input size\n",
    "        with torch.no_grad():\n",
    "            conv_output = self.forward_conv(dummy_input)\n",
    "        num_features_after_conv = conv_output.view(1, -1).size(1)\n",
    "        return num_features_after_conv   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc78fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "class PNWDataSet(Dataset): # create custom dataset\n",
    "    def __init__(self, data,labels): # initialize\n",
    "        self.data = data \n",
    "        self.labels = labels \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_data = self.data[index]\n",
    "        sample_labels = self.labels[index]\n",
    "        return torch.Tensor(sample_data),(sample_labels) # return data as a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a default 3000 waveforms per class.\n",
    "# there are 4 classes.\n",
    "# we will do 80-10-10 split.\n",
    "\n",
    "def prepare_datasets(data_noise=\"/data/whd01/yiyu_data/PNWML/noise_waveforms.hdf5\", medata_noise=\"/data/whd01/yiyu_data/PNWML/noise_metadata.csv\", \n",
    "                     data_comcat=  \"/data/whd01/yiyu_data/PNWML/comcat_waveforms.hdf5\", metadata_comcat=\"/data/whd01/yiyu_data/PNWML/comcat_metadata.csv\", data_exotic=\"/data/whd01/yiyu_data/PNWML/exotic_waveforms.hdf5\",\n",
    "                     metadata_exotic=\"/data/whd01/yiyu_data/PNWML/exotic_metadata.csv\",\n",
    "                     before = 5000, after = 10000, num_samples = 3000, batch_size = 32, \n",
    "                     num_channels = 3, train_split = 80, val_split=10,test_split = 10, num_features = 5000, \n",
    "                     shifting = True, all_samples = True):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a function to extract train, test and validation dataset in tensor format as required by Pytorch\n",
    "    Here is a description of the parameters: - \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    \n",
    "    before: if shifting is not true, samples will be extracted (P-50), \n",
    "    where P refers to the starttime of the P/pick time of the event.\n",
    "    The shifting helps in generalizability of the model. The samples will be picked randomly from\n",
    "    (P-20, P-5)    \n",
    "    after: if shifting is not true, samples will be extracted (P+100)    \n",
    "    num_samples: number of samples per classs to extract    \n",
    "    batch size: batch size of the samples that would be loaded in one iteration from the dataloader    \n",
    "    num_channels: 1, Currently just using the Z component, but we can use multiple channels. \n",
    "    train_size: its the number of elements (per class) in the training dataset on the first split.  (splitting the dataset into train and temp)    \n",
    "    test_size: its the number of elements (per class) in the testing dataset on the second split. (splitting the temp further into test and val)\n",
    "    num_features: The number of features or window length.     \n",
    "    shifting: If true, the samples will be extracted randomly from P-5, P-20s    \n",
    "    all_samples: if true, all the samples will be loaded in each class\n",
    "    \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_dataset: the dataset containing the examples on which the model was trained. \n",
    "    It contains the features and corresponding samples, the size of the training dataset would be  4*train_size\n",
    "    \n",
    "    train_dataloader: The dataloader is required when training the model, taking a batch of the samples at a given time. \n",
    "    \n",
    "    y_train: the training labels,  \n",
    "    \n",
    "    test_dataset, test_dataloader, y_test: self explanatory, the size of test will be determined by the 4*test_size parameter. \n",
    "    \n",
    "    val_dataset, val_dataloader, y_val: self explanatory, the size of validation set would be determined as \n",
    "      (total_samples - 4*train_size - 4*test_size)\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    noise_metadata = pd.read_csv(metadata_noise)\n",
    "    noise_metadata['event_id'] = [noise_metadata['trace_start_time'][i]+'_noise' for i in range(len(noise_metadata))]\n",
    "\n",
    "    # accessing the data files\n",
    "    comcat_metadata = pd.read_csv(metadata_comcat)\n",
    "\n",
    "    # accessing the data files\n",
    "    exotic_metadata = pd.read_csv(metadata_exotic)\n",
    "    \n",
    "    cat_exp = comcat_metadata[comcat_metadata['source_type'] == 'explosion']\n",
    "    cat_eq = comcat_metadata[comcat_metadata['source_type'] == 'earthquake']\n",
    "    cat_su = exotic_metadata[exotic_metadata['source_type'] == 'surface event']\n",
    "    \n",
    "    \n",
    "    #extract wavefpr,s\n",
    "    ## So in the below I am taking a 50s window which starts anywhere randomly from (P-20, P-5) - \n",
    "    ## a is a list of obspy traces, b is a list of eventid\n",
    "    \n",
    "    a_noise, b_noise = extract_waveforms(noise_metadata, data_noise, num_features = num_features, start = 5000, before = before, after = after, number_samples = num_samples, num_channels = num_channels, shifting = shifting, all_samples = all_samples)\n",
    "    \n",
    "    a_exp, b_exp = extract_waveforms(cat_exp, data_comcat, num_features = num_features, start = 5000, before = before, after = after, number_samples = num_samples, num_channels = num_channels, shifting = shifting, all_samples = all_samples)\n",
    "    \n",
    "    a_eq, b_eq = extract_waveforms(cat_eq, data_comcat, num_features = num_features,  start = 5000, before = before, after = after, number_samples = num_samples, num_channels = num_channels, shifting = shifting, all_samples = all_samples)\n",
    "    \n",
    "    a_su, b_su = extract_waveforms(cat_su, data_exotic, num_features = num_features, start = 7000, before = before, after = after, number_samples = num_samples, num_channels = num_channels, shifting = shifting, all_samples = all_samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # stacking the data\n",
    "    d_noise = np.stack(a_noise)\n",
    "    d_exp = np.stack(a_exp)\n",
    "    d_eq = np.stack(a_eq)\n",
    "    d_su = np.stack(a_su)\n",
    "\n",
    "    \n",
    "    if num_channels == 1:\n",
    "        d_noise = d_noise[:, np.newaxis, :]\n",
    "        d_exp = d_exp[:, np.newaxis, :]\n",
    "        d_eq = d_eq[:, np.newaxis, :]\n",
    "        d_su = d_su[:, np.newaxis, :]\n",
    "    \n",
    "    # remove zero data, which is only necessary if we just use single-comp sensors, and I am not even sure it would be necessary actually...\n",
    "    d_noise = retain_nonzero_arrays(d_noise)\n",
    "    d_exp = retain_nonzero_arrays(d_exp)\n",
    "    d_eq = retain_nonzero_arrays(d_eq)\n",
    "    d_su = retain_nonzero_arrays(d_su)\n",
    "    \n",
    "    X = np.vstack([d_noise, d_exp, d_eq, d_su])\n",
    "    \n",
    "    tapered = apply_cosine_taper(X)\n",
    "    filtered = butterworth_filter(tapered, lowcut = 1, highcut = 10, fs = 100, num_corners = 4, filter_type='bandpass')\n",
    "    data = normalize_arrays_by_max(filtered)\n",
    "  \n",
    "    \n",
    "    # labels to encode   \n",
    "    y = ['noise']*len(d_noise)+['explosion']*len(d_exp)+['earthquake']*len(d_eq)+['surface']*len(d_su)\n",
    "    event_ids = np.hstack([b_noise, b_exp, b_eq, b_su])\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Make the data a PNWDataSet\n",
    "    custom_dataset = PNWDataSet(data,y)\n",
    "    # first split train+val\n",
    "    train_dataset_torch, val_dataset = random_split(custom_dataset, [train_size, test_size+val_size])\n",
    "    # then split val into val+test\n",
    "    test_dataset, val_dataset = random_split(val_dataset, [test_size,val_size])\n",
    "    \n",
    "#     # below was before\n",
    "#     # Split data into training and testing sets\n",
    "#     train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "\n",
    "#     train_data, temp_data, y_train, y_temp = train_test_split(data, y,  test_size= 4*num_samples - 4*train_size, random_state=42)\n",
    "#     val_data, test_data, y_val, y_test = train_test_split(temp_data, y_temp, test_size = 4*test_size, random_state = 42)\n",
    "\n",
    "    \n",
    "#     label_encoder = LabelEncoder()\n",
    "\n",
    "#     # Create TensorDataset and DataLoader for training data\n",
    "#     train_labels = y_train # Define your training labels\n",
    "#     train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "#     train_labels = torch.Tensor(train_labels_encoded) # Suitable for use in pytorch. \n",
    "\n",
    "#     train_data = torch.Tensor(train_data)\n",
    "\n",
    "#     train_dataset = TensorDataset(train_data, train_labels) # Combines the training data and the numerical labels into \n",
    "#     # single dataset. \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # it allows you to efficiently iterate \n",
    "#     # through the data in mini-batches during training. \n",
    "\n",
    "    \n",
    "#     # Similarly, create a DataLoader for validation data\n",
    "#     val_labels = y_val\n",
    "#     val_labels_encoded = label_encoder.fit_transform(val_labels)\n",
    "#     val_labels = torch.Tensor(val_labels_encoded)\n",
    "    \n",
    "#     val_data = torch.Tensor(val_data)\n",
    "#     val_dataset = TensorDataset(val_data, val_labels)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    # Create a DataLoader\n",
    "    data_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    data_loader_val = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    data_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "#     # Similarly, create a DataLoader for testing data\n",
    "#     test_labels = y_test  # Define your testing labels\n",
    "#     test_labels_encoded = label_encoder.fit_transform(test_labels)\n",
    "#     test_labels = torch.Tensor(test_labels_encoded)\n",
    "\n",
    "#     test_data = torch.Tensor(test_data)\n",
    "\n",
    "#     test_dataset = TensorDataset(test_data, test_labels)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return data_loader_train,data_loader_val,data_loader_test\n",
    "    \n",
    "#     return train_dataset, train_loader, y_train, test_dataset, test_loader, y_test, val_dataset, val_loader, y_val, event_ids\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571104de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_waveforms(cat, file_name, start=7000, num_features=5000, before=5000, after=10000, number_samples=1000, num_channels=1, all_samples=False, shifting=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a function defined to extract the waveforms stored in the disk. \n",
    "    Inputs:\n",
    "    cat -  Catalog containing metadata of the events, so we can extract the data using the bucket information\n",
    "    file_name - path of the h5py file containing the data\n",
    "    start - origin or first arrival time\n",
    "    num_features - window length to extract\n",
    "    before - number of samples to take before the arrival time\n",
    "    after - number of samples to take after the arrival time.\n",
    "    num_samples - no. of events per class to extract\n",
    "    num_channels - no. of channels per event to extract, if set 1, will extract Z component, if set any other number, will extract - ZNE component. \n",
    "    all_samples - if true, will extract all the samples corresponding of a given class\n",
    "    shifting - if true, will extract windows randomly starting between P-5, P-20. The random numbers follow a gaussian distribution. \n",
    "    Outputs:\n",
    "    \n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    # This line initializes empty lists to store waveform data (not traces as in obspy definition)\n",
    "    st = []    \n",
    "    # This line initializes empty list to store corresponding event ids. \n",
    "    event_ids = []    \n",
    "    \n",
    "    # This line opens an HDF5 file in read only mode, the with statement ensures that the file is properly\n",
    "    # closed after the block of code is executed. \n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        cat_trace = cat['trace_name'].values        \n",
    "        \n",
    "        # If all_samples flag is true, it assigns the values equal to the length of cat_trace to number_samples\n",
    "        if all_samples:\n",
    "            number_samples = len(cat_trace)\n",
    "            \n",
    "        # Generates a list of random integers between 500 and 2000 (inclusive) if shifting flag is true, otherwise\n",
    "        # it will generate a list of before equal to number_samples in the length. \n",
    "        \n",
    "        # Note that the np.full function is defined to create a numpy array of specific shape and fill it with a constant value. \n",
    "        random_integer_list = np.random.randint(500, 2001, size=number_samples) if shifting else np.full(number_samples, before)\n",
    "        \n",
    "        # Note - so since we are taking the first number_samples from the dataset mainly for training,\n",
    "        # it may include some temporal bias, in future. a to-do will be to randomize this extraction. \n",
    "        for i in tqdm(range(number_samples)):\n",
    "            \n",
    "            # taking the before samples\n",
    "            before = random_integer_list[i]\n",
    "            \n",
    "            # taking the after samples\n",
    "            after = num_features - before\n",
    "            \n",
    "            # so this code is taking the trace information and splitting it using the $ delimiter\n",
    "            # because the trace bucket and index are split. \n",
    "            \n",
    "            \n",
    "            ## here is really a random sampling.\n",
    "            ii = np.random.randint(len(cat_trace))\n",
    "            \n",
    "            trace_info = cat_trace[ii].split('$')\n",
    "            \n",
    "            # storing the bucket information\n",
    "            bucket = trace_info[0]\n",
    "            \n",
    "            # storing the index information, \n",
    "            ind = int(trace_info[1].split(',')[0])\n",
    "\n",
    "            if num_channels == 1:\n",
    "                z_component = f['/data/'+bucket][ind, 2, start - before: start + after]\n",
    "                \n",
    "                # This is a kind of quality check applied on the data. \n",
    "                # we can also apply some other kind of quality check at this stage. \n",
    "                if np.sum(z_component) != 0:\n",
    "                    event_ids.append(cat['event_id'].values[ii])\n",
    "                    st.append(z_component)\n",
    "            else:\n",
    "                trace_data = f['/data/'+bucket][ind, :, start - before: start + after]\n",
    "                if np.sum(trace_data) != 0:\n",
    "                    event_ids.append(cat['event_id'].values[ii])\n",
    "                    st.append(trace_data)\n",
    "\n",
    "    return st, event_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d19086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_dataset, val_loader, optimizer, n_epochs=100, batch_size=32, num_input=15000, num_channels=3,criterion=nn.CrossEntropyLoss()):\n",
    "    \"\"\"\n",
    "    Function to train and evaluate the defined model.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for training data.\n",
    "        val_dataset (torch.utils.data.Dataset): Validation dataset.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for validation data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for training the model.\n",
    "        n_epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        number_input (int): Number of points in the input data.\n",
    "        num_channels (int): Number of channels in the input data.\n",
    "\n",
    "    Returns:\n",
    "        accuracy_list (list): List of accuracies computed from each epoch.\n",
    "        train_loss_list (list): List of training losses from each epoch.\n",
    "        val_loss_list (list): List of validation losses from each epoch.\n",
    "        y_pred (list): List of predicted values.\n",
    "        y_true (list): List of true values.\n",
    "    \"\"\"\n",
    "    # Check if a GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    N_test = len(val_dataset)\n",
    "\n",
    "    # to store the accuracies computed from each epoch.\n",
    "    accuracy_list = []\n",
    "\n",
    "    # to store the losses from each epoch.\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    # to store the predicted values\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss_data = 0\n",
    "        for x, y in train_loader:\n",
    "            # setting the variable to run on GPU.\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # setting the model in training mode.\n",
    "            model.train()\n",
    "\n",
    "            # setting the gradients to zero.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # computing the output\n",
    "            z = model(x.view(x.shape[0], num_channels, num_features))\n",
    "\n",
    "            # converting the labels to standard type.\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "            # computing the loss\n",
    "            loss = criterion(z, y)\n",
    "\n",
    "            # computing the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # updating the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_data += loss.data.cpu().numpy()\n",
    "\n",
    "        # updating the training loss list\n",
    "        train_loss_list.append(train_loss_data / len(train_loader))\n",
    "\n",
    "        val_loss_data = 0\n",
    "        correct = 0\n",
    "        for x_test, y_test in val_loader:\n",
    "            # setting the model in evaluation mode.\n",
    "            model.eval()\n",
    "\n",
    "            # pass the data to GPU\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "            # computing the output.\n",
    "            z = model(x_test.view(x_test.shape[0], num_channels, num_features))\n",
    "            \n",
    "             # Convert z to 'Float' data type and y_test to 'Long' data type\n",
    "            z = z.to(torch.float)\n",
    "            y_test = y_test.to(torch.long)\n",
    "\n",
    "            # computing the loss\n",
    "            val_loss = criterion(z, y_test)\n",
    "            val_loss_data += val_loss.data.cpu().numpy()\n",
    "\n",
    "            # computing the number of correct predictions.\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "            y_pred.append(yhat.cpu().numpy())\n",
    "            y_true.append(y_test.cpu().numpy())\n",
    "\n",
    "        # updating the validation loss list\n",
    "        val_loss_list.append(val_loss_data / len(val_loader))\n",
    "\n",
    "        accuracy = correct / N_test\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    return accuracy_list, train_loss_list, val_loss_list, y_pred, y_true\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50031aa0",
   "metadata": {},
   "source": [
    "## Defining some common parameters for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13429d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epochs = 100\n",
    "# Define the loss function (e.g., Cross-Entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f460ef4",
   "metadata": {},
   "source": [
    "## Training and Testing all the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edd15a",
   "metadata": {},
   "source": [
    "## Archtime (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9fbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archtime_normal\n",
    "num_channels = 1\n",
    "number_features = 5000\n",
    "\n",
    "#train_dataset, train_loader, test_dataset, test_loader, val_dataset, val_loader = extract_datasets(num_channels = 1, num_samples = 5000)\n",
    "#train_dataset, train_loader, y_train, test_dataset, test_loader, y_test,  val_dataset, val_loader, y_val = extract_datasets(before = 1000, after = 40000, num_samples = 5000, batch_size = 32, num_channels = 1, train_size = 4000, test_size = 0, num_features = 5000, shifting = True)\n",
    "\n",
    "\n",
    "data_loader_train,data_loader_val,data_loader_test = prepare_datasets()\n",
    "\n",
    "\n",
    "# train_dataset, train_loader, y_train, test_dataset, test_loader, y_test,  val_dataset, val_loader, y_val, event_ids_normal = extract_datasets(before = 1000, after = 4000, num_samples = 5500, batch_size = 32, num_channels = 1, train_size = 5000, test_size = 1, num_features = 5000, shifting = True, all_samples = False)\n",
    "\n",
    "\n",
    "model_archtime = Archtime(num_channels = 3, num_input = 5000)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model_archtime.parameters(), lr=0.001)\n",
    "accuracy_archtime, train_loss_archtime, val_loss_archtime, y_pred, y_true  = train_model(model_archtime, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea5f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f3f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ed0c05",
   "metadata": {},
   "source": [
    "## Archtime (with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archtime_dropout\n",
    "num_channels = 1\n",
    "number_features = 5000\n",
    "\n",
    "#train_dataset, train_loader, test_dataset, test_loader, val_dataset, val_loader = extract_datasets(num_channels = 1, num_samples = 5000)\n",
    "#train_dataset, train_loader, y_train, test_dataset, test_loader, y_test,  val_dataset, val_loader, y_val, event_ids_norma = extract_datasets(before = 1000, after = 4000, num_samples = 5500, batch_size = 32, num_channels = 1, train_size = 5000, test_size = 1, num_features = 5000, shifting = True, all_samples = False)\n",
    "\n",
    "\n",
    "model_archtime_do = Archtime_do(num_channels = 1, num_features = 5000)\n",
    "optimizer = torch.optim.Adam(model_archtime_do.parameters(), lr=0.001)\n",
    "accuracy_archtime_do, train_loss_archtime_do, val_loss_archtime_do, y_pred, y_true  = train_model(model_archtime_do, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7121daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374e1b5c",
   "metadata": {},
   "source": [
    "## Wavedecompnet (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wavedecompnet = WaveDecompNet(num_channels = 1, num_features = 5000)\n",
    "optimizer = torch.optim.Adam(model_wavedecompnet.parameters(), lr=0.001)\n",
    "accuracy_wavedecompnet, train_loss_wavedecompnet, val_loss_wavedecompnet, y_pred, y_true  = train_model(model_wavedecompnet, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bfbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17066ee0",
   "metadata": {},
   "source": [
    "## WaveDecompNet (with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wavedecompnet_do = WaveDecompNet_do(num_channels = 1, num_features = 5000)\n",
    "optimizer = torch.optim.Adam(model_wavedecompnet_do.parameters(), lr=0.001)\n",
    "accuracy_wavedecompnet_do, train_loss_wavedecompnet_do, val_loss_wavedecompnet_do, y_pred, y_true  = train_model(model_wavedecompnet_do, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b930c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c1a48bd",
   "metadata": {},
   "source": [
    "## SeismicCNN_batch (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seismiccnn_batch = SeismicCNN_batch(num_channels = 1)\n",
    "optimizer = torch.optim.Adam(model_seismiccnn_batch.parameters(), lr=0.001)\n",
    "accuracy_seismiccnn_batch, train_loss_seismiccnn_batch, val_loss_seismiccnn_batch, y_pred, y_true  = train_model(model_seismiccnn_batch, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38df78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee36411",
   "metadata": {},
   "source": [
    "## SeismicCNN_batch (with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seismiccnn_batch_do = SeismicCNN_batch_do(num_channels = 1)\n",
    "optimizer = torch.optim.Adam(model_seismiccnn_batch_do.parameters(), lr=0.001)\n",
    "accuracy_seismiccnn_batch_do, train_loss_seismiccnn_batch_do, val_loss_seismiccnn_batch_do, y_pred, y_true  = train_model(model_seismiccnn_batch_do, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ff8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6ed5698",
   "metadata": {},
   "source": [
    "## SeismicNet (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seismicne dropout\n",
    "num_channels = 1\n",
    "number_features = 15000\n",
    "\n",
    "#train_dataset, train_loader, test_dataset, test_loader, val_dataset, val_loader = extract_datasets(num_channels = 1, num_samples = 5000)\n",
    "\n",
    "train_dataset, train_loader, y_train, test_dataset, test_loader, y_test,  val_dataset, val_loader, y_val, event_ids_seismicnet = extract_datasets(before = 5000, after = 10000, num_samples = 5000, batch_size = 32, num_channels = 1, train_size = 4000, test_size = 1, num_features = 15000, shifting = False, all_samples = False)\n",
    "model_seismicnet = SeismicNet(num_channels = 1, num_features = 15000)\n",
    "optimizer = torch.optim.Adam(model_seismicnet.parameters(), lr=0.001)\n",
    "accuracy_seismicnet, train_loss_seismicnet, val_loss_seismicnet, y_pred, y_true  = train_model(model_seismicnet, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a2a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49846045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc8c75a",
   "metadata": {},
   "source": [
    "## SeismicNet (with dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b624249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataset will contain the features and corresponding labels. \n",
    "# We can access the elements in the dataset by specifying the index. \n",
    "# A dataloader - split the whole datasets into batches of specified sizes and shuffle randomly.\n",
    "\n",
    "\n",
    "model_seismicnet_do = SeismicNet_do(num_channels = 1, num_features = 15000)\n",
    "optimizer = torch.optim.Adam(model_seismicnet_do.parameters(), lr=0.001)\n",
    "accuracy_seismicnet_do, train_loss_seismicnet_do, val_loss_seismicnet_do, y_pred, y_true  = train_model(model_seismicnet_do, train_loader, val_dataset, val_loader, optimizer, n_epochs = number_epochs, num_channels = num_channels, num_features = 15000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdd682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f28040c5",
   "metadata": {},
   "source": [
    "## Plotting the performance of individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41539f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Archtime models\n",
    "plot_train_val_loss(train_loss_archtime, val_loss_archtime, title = 'Archtime (original)')\n",
    "plot_train_val_loss(train_loss_archtime_do, val_loss_archtime_do, title = 'Archtime with dropout')\n",
    "\n",
    "\n",
    "# SeismicCNN_batch\n",
    "plot_train_val_loss(train_loss_seismiccnn_batch, val_loss_seismiccnn_batch, title = 'SeismicCNN_batch (original)')\n",
    "plot_train_val_loss(train_loss_seismiccnn_batch_do, val_loss_seismiccnn_batch_do, title = 'SeismicCNN_batch (original)')\n",
    "\n",
    "\n",
    "# WaveDecompNet\n",
    "plot_train_val_loss(train_loss_wavedecompnet, val_loss_wavedecompnet, title = 'WaveDecompNet (original)')\n",
    "plot_train_val_loss(train_loss_wavedecompnet_do, val_loss_wavedecompnet_do, title = 'WaveDecompent (with dropout)')\n",
    "\n",
    "\n",
    "# SeismicNet\n",
    "plot_train_val_loss(train_loss_seismicnet, val_loss_seismicnet, title = 'SeismicNet (original)')\n",
    "plot_train_val_loss(train_loss_seismicnet_do, val_loss_seismicnet_do, title = 'SeismicNet (with dropout)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a070ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(accuracy_archtime, accuracy_archtime_do, label1 = 'Archtime (original)', label2 = 'Archtime (with dropout)')\n",
    "\n",
    "plot_accuracy(accuracy_seismiccnn_batch, accuracy_seismiccnn_batch_do, label1 = 'SeismicCNN (original)', label2 = 'SeismicCNN (with dropout)')\n",
    "\n",
    "\n",
    "plot_accuracy(accuracy_wavedecompnet, accuracy_wavedecompnet_do, label1 = 'WaveDecompNet (original)', label2 = 'WaveDecompNet (with dropout)')\n",
    "\n",
    "\n",
    "plot_accuracy(accuracy_seismicnet, accuracy_seismicnet_do, label1 = 'SeismicNet (original)', label2 = 'SeismicNet (with dropout)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bd817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597edbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d0bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnw_class",
   "language": "python",
   "name": "pnw_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
